# This workflow will build and upload nodejs application on the github's npm registry.

name: Build and Upload NodeJS PNPM Applications

on:
  workflow_call:
    inputs:
      #
      # Common settings
      #
      app-name:
        description: |
          Application name in human-readable form.
          As it is supposed to be shown in messages
        type: string
        required: false
        default: ${{ github.repository }}

      app-name-slug:
        description: |
          Application name slug (part of release file name)
        type: string
        required: true

      gha-runner-label:
        description: |
          The label for github actions hosted runner
        type: string
        default: 'ubuntu-latest'

      #
      # Checkout settings
      #
      checkout-submodules:
        description: |
          'Submodules' mode for 'actions/checkout' action
          '', 'false' - disable submodules support
          'true' - checkout submodules
          'recursive' - checkout submodules recursive
        type: string
        required: false
        default: ''

      checkout-git-lfs:
        description: |
          Use git lfs when checking-out the repository
        type: string
        required: false
        default: 'false'

      #
      # Environment settings
      #
      env:
        description: |
          custom environment variables to set for all jobs in workflow
          as JSON-encoded map:
            { "MY_VAR_1": "awesome value",
              "VARIABLE_2": "not so awesome :)" }

          This input's envs are merged with secrets.env
          This input's envs have lower priority compared than secrets.env
        type: string
        required: false
        default: '{}'

      #
      # NodeJS settings
      #
      node-version:
        description: |
          Node version to use
        type: string
        required: true

      #
      # Golang settings
      #
      golang-version:
        description: |
          Node version to use.
          Examples: '1.19', '1.20'
        type: string
        required: false

      golang-cache-hashfiles-path:
        description: |
          Returns a single hash for the set of files that matches the path pattern.
          You can provide a single path pattern or multiple path patterns separated by commas.
          The path is relative to the GITHUB_WORKSPACE directory
          and can only include files inside of the GITHUB_WORKSPACE.
        type: string
        required: false
        default: '**/go.sum'

      #
      # Cache control
      #
      cache-version:
        description: |
          Simple hack, that allows to 'reset' cache for particular job.

          Just change the value of this parameter and the next run will
          not find build cache and will have to start from scratch.

        type: string
        required: false
        default: 'v1'

      cache-hashfiles-search-path:
        description: |
          Hashfiles search path for pnpm-lock.yaml
        type: string
        required: false
        default: 'pnpm-lock.yaml'

      team-id:
        description: |
          The Team ID to use. This controls the directory where turbo cache entries will be saved
        type: string
        required: false
        default: 'ci'

      #
      # PNPM settings
      #
      pnpm-version:
        description: |
          Version of pnpm to install.
        type: string
        required: false
        default: 'latest'

      pnpm-recursive-build:
        description: |
          Run pnpm build with -r flag.
        type: boolean
        required: true

      pnpm-recursive-tests:
        description: |
          Run pnpm tests with -r flag.
        type: boolean
        required: true

      pnpm-build-args:
        description: |
          Additional pnpm build arguments to pass
          for none --recursive pnpm invocations.
        type: string
        required: false

      pnpm-tests-args:
        description: |
          Additional pnpm tests arguments to pass
          for none --recursive pnpm invocations.
        type: string
        required: false

      #
      # Build control
      #
      build-script-name:
        description: |
          The name of a build script
        type: string
        required: true
        default: 'build'

      build-before-publish-script-name:
        description: |
          The name of a build before publish script
        type: string
        required: false

      is-electron-application:
        description: |
          If 'true' enables cache for an Electron application,
          if 'false', enables cache for a generic NodeJS application.
        type: string
        required: false
        default: 'true'

      #
      # Build pre-calculated control
      #
      pre-calculated:
        description:
          Flag to indicate whether individual subtasks are pre-calculated on isolated nodes
          to enable parallel builds within a monorepo workflow. Set to true to activate pre-calculation.
        type: boolean
        required: false
        default: false

      pre-calculated-task-list:
        description:
          JSON-formatted string listing of the specific subtasks that have been pre-calculated.
          This list is used to manage and track the execution of parallel builds in the monorepo.
        type: string
        required: false
        default: '[]'

      #
      # Test control
      #
      test:
        description: |
          Run tests
        type: boolean
        required: false
        default: false

      test-script-name:
        description: |
          The name of a test
        type: string
        required: false
        default: 'test'

      test-dry-run-script-name:
        description: |
          The name of a test dry-run script
        type: string
        required: false
        default: 'test:dry-run'

      test-skip-dry-run:
        description: |
          Skip test dry-run step
        type: string
        required: false
        default: 'false'

      test-coverage:
        description: |
          Whether to upload coverage reports to Codecov.
        type: boolean
        required: false
        default: false

      test-coverage-reports:
        description: |
          Comma-separated list of coverage report files to upload to Codecov.
          If empty, no coverage reports will be uploaded.
        type: string
        required: false
        default: ''

      test-results-reports:
        description: |
          Comma-separated list of test results report files to upload to Codecov.
          If empty, no test results reports will be uploaded.
        type: string
        required: false
        default: ''

      #
      # NPM registry settings
      #
      npmrc-config:
        description: |
          Generates a .npmrc file based on provided configuration.
        type: string
        required: true

      #
      # Distribution control
      #
      publish-to-public:
        description: |
          Whether or not the npm package should be published as public.
        type: string
        required: false
        default: 'false'

      create-tag:
        description: |
          Create a tag after publishing the package.
        type: string
        required: false
        default: 'false'

      package-path:
        description: |
          Relative path to the package.json with package version.
        type: string
        required: false
        default: '.'

      aws-region:
        description: |
          The AWS region
        type: string
        required: false
        default: 'eu-central-1'

      aws-login-duration:
        description: |
          Maximum time AWS credentials will be valid until expiration.
          Defaults to 1 hour.
        type: number
        required: false
        default: 3600

      #
      # Platforma Docker settings
      #
      pl-start-for-tests:
        description: |
          Start Platforma Backend instance for tests
        type: boolean
        required: false
        default: true

      pl-docker-tag:
        description: |
          Platforma docker tag.
        type: string
        required: false
        default: 'main'

      pl-test-assets-dir:
        description: |
          Platforma test assets directory;
          this directory will be mounted inside
          the container under the path `/storage/controllers/data/library`
          The path must be relative to github.workspace
          and will be appended to github.workspace within the docker compose action.
        type: string
        required: false
        default: 'assets'

      pl-log-level:
        description: |
          Platforma log level for tests.
          Examples: 'debug', 'info', 'warn', 'error'
        type: string
        required: false
        default: 'info'

      #
      # Changed files
      #
      changeset-default-branch:
        description:
          Specify the default branch for changesets to run checks against.
        type: string
        required: false
        default: 'main'

      require-review:
        description: |
          Whether or not to require a review for the PR.
        type: boolean
        required: false
        default: false

      #
      # Docker settings
      #
      docker-quay-push:
        description: |
          Whether or not to push images to quay.io registry.
        type: boolean
        required: false
        default: true

      docker-ga-push:
        description: |
          Whether or not to push images to GA registry.
        type: boolean
        required: false
        default: true

      notify-slack:
        description: |
          Enable Slack notifications
        required: false
        type: boolean
        default: true

      cache-monitoring:
        description: |
          Enable Turbo S3 cache monitoring.
          When enabled, the workflow will track cache hits/misses
          and alert if multiple consecutive merge queue runs
          execute without cache.
        required: false
        type: boolean
        default: false

    secrets:
      env:
        description: |
          custom environment variables to set for all jobs in workflow
          as JSON-encoded map:
            { "MY_VAR_1": "awesome value",
              "VARIABLE_2": "not so awesome :)" }

          This input's envs are merged with inputs.env
          This input's envs have HIGHER priority compared than inputs.env
        required: false

      SLACK_BOT_TOKEN:
        description: |
          Slack bot token for notifications
        required: false
      SLACK_CHANNEL:
        description: |
          Slack channel for notifications
        required: false
      GH_ZEN_APP_ID:
        description: |
          Zen Artisian Github AppID
        required: false
      GH_ZEN_APP_PRIVATE_KEY:
        description: |
          Zen Artisian Github App PrivateKey
        required: false

jobs:
  init:
    name: Init
    runs-on: ubuntu-latest
    steps:
      - id: context
        uses: milaboratory/github-ci/actions/context@v4-beta
    outputs:
      is-release: ${{ steps.context.outputs.is-release }}
      current-version: ${{ steps.context.outputs.current-version }}

  metadata:
    name: get run metadata
    runs-on: ubuntu-latest
    needs:
      - init
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: ${{ inputs.checkout-git-lfs }}
          submodules: ${{ inputs.checkout-submodules }}

      - id: npm-pkg-metadata
        uses: milaboratory/github-ci/actions/shell@v4-beta
        env:
          PACKAGE_PATH: ${{ inputs.package-path }}
        with:
          run: |
            NPM_PKG_VERSION="$(cat "${GITHUB_WORKSPACE}/${PACKAGE_PATH}/package.json" | jq --raw-output '.version')"
            PNPM_VERSION="$(cat "${GITHUB_WORKSPACE}/package.json" | jq --raw-output 'if .packageManager and (.packageManager | length > 0) then .packageManager | split("@")[1] else empty end')"
            ghwa_set_output npm-pkg-version "${NPM_PKG_VERSION}"
            ghwa_set_output pnpm-version "${PNPM_VERSION}"

    outputs:
      npm-pkg-version: ${{ fromJSON(steps.npm-pkg-metadata.outputs.data).npm-pkg-version }}
      pnpm-version: ${{ fromJSON(steps.npm-pkg-metadata.outputs.data).pnpm-version }}

  check-changesets:
    name: check for changesets
    runs-on: ubuntu-latest
    needs:
      - metadata
    if: github.ref_name == 'main' || github.event_name == 'merge_group'
    steps:
      - id: context
        uses: milaboratory/github-ci/actions/context@v4-beta

      - uses: milaboratory/github-ci/actions/env@v4-beta
        with:
          inputs: ${{ inputs.env }}
          secrets: ${{ secrets.env }}

      - uses: actions/checkout@v4
        with:
          lfs: ${{ inputs.checkout-git-lfs }}
          submodules: ${{ inputs.checkout-submodules }}
          fetch-depth: '0'

      - name: Prepare environment for building a NodeJS application
        uses: milaboratory/github-ci/actions/node/prepare-pnpm@v4-beta
        env:
          PNPM_VERSION: ${{ needs.metadata.outputs.pnpm-version }}
        with:
          node-version: ${{ inputs.node-version }}
          cache-version: ${{ inputs.cache-version }}
          pnpm-version: ${{ env.PNPM_VERSION || inputs.pnpm-version }}
          cache-hashfiles-search-path: ${{ inputs.cache-hashfiles-search-path }}
          npmrc-config: ${{ inputs.npmrc-config }}

      - name: Install NodeJS packages with pnpm
        uses: milaboratory/github-ci/actions/shell@v4-beta
        with:
          run: |
            pnpm install --frozen-lockfile --prefer-offline

      - name: Check for Changesets
        uses: milaboratory/github-ci/actions/shell@v4-beta
        env:
          BRANCH_NAME: ${{ inputs.changeset-default-branch }}
        with:
          run: |
            pnpm changeset status --since="origin/${BRANCH_NAME}"

  pre-calculated-build:
    name: pre-build
    runs-on: ${{ inputs.gha-runner-label }}
    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJSON(inputs.pre-calculated-task-list) }}
    needs:
      - check-changesets
      - metadata
    if: >
      inputs.pre-calculated && inputs.pre-calculated-task-list != '[]' &&
      !failure() && !cancelled() &&
      (
        needs.check-changesets.result == 'success' ||
        needs.check-changesets.result == 'skipped'
      )
    permissions:
      id-token: write
      contents: read
    steps:
      - uses: milaboratory/github-ci/actions/env@v4-beta
        with:
          inputs: ${{ inputs.env }}
          secrets: ${{ secrets.env }}

      - name: Generate Zen Artisan Token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.GH_ZEN_APP_ID }}
          private-key: ${{ secrets.GH_ZEN_APP_PRIVATE_KEY }}

      - uses: actions/checkout@v4
        with:
          lfs: ${{ inputs.checkout-git-lfs }}
          submodules: ${{ inputs.checkout-submodules }}
          token: ${{ steps.app-token.outputs.token }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_CI_IAM_MONOREPO_SIMPLE_ROLE }}
          role-duration-seconds: ${{ inputs.aws-login-duration }}
          aws-region: ${{ inputs.aws-region }}

      - id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
        with:
          mask-password: 'true'

      - name: Login to Quay.io
        if: inputs.docker-quay-push && env.QUAY_USERNAME != '' && env.QUAY_ROBOT_TOKEN != ''
        uses: docker/login-action@v3
        with:
          registry: quay.io
          username: ${{ env.QUAY_USERNAME }}
          password: ${{ env.QUAY_ROBOT_TOKEN }}
          ecr: false

      - name: Login to Docker GA
        if: inputs.docker-ga-push && env.QUAY_USERNAME != '' && env.QUAY_ROBOT_TOKEN != ''
        uses: docker/login-action@v3
        with:
          registry: containers.pl-open.science
          username: ${{ env.QUAY_USERNAME }}
          password: ${{ env.QUAY_ROBOT_TOKEN }}
          ecr: false

      - uses: milaboratory/github-ci/actions/turborepo/cache-s3@v4-beta
        with:
          storage-provider: 's3'
          storage-path: ${{ env.AWS_CI_TURBOREPO_S3_BUCKET }}
          team-id: ${{ inputs.team-id }}

      - name: Prepare environment for building a NodeJS application
        uses: milaboratory/github-ci/actions/node/prepare-pnpm@v4-beta
        env:
          PNPM_VERSION: ${{ needs.metadata.outputs.pnpm-version }}
        with:
          node-version: ${{ inputs.node-version }}
          cache-version: ${{ inputs.cache-version }}
          pnpm-version: ${{ env.PNPM_VERSION || inputs.pnpm-version }}
          cache-hashfiles-search-path: ${{ inputs.cache-hashfiles-search-path }}
          npmrc-config: ${{ inputs.npmrc-config }}

      - name: Install NodeJS packages with pnpm
        shell: bash
        env:
          NODE_AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NPMJS_TOKEN: ${{ env.NPMJS_TOKEN  }}
          DEFAULT_BRANCH: origin/${{ inputs.changeset-default-branch }}

        run: |
          if git diff --name-only ${DEFAULT_BRANCH}..HEAD | grep -q -E '^pnpm-workspace.yaml$'; then
            # Changes in pnpm-workspace.yaml have to be accompanied by pnpm-lock.yaml update
            if ! git diff --name-only ${DEFAULT_BRANCH}..HEAD | grep -q -E '^pnpm-lock.yaml$'; then
              echo "Changes in pnpm-workspace.yaml detected, but no updates in pnpm-lock.yaml were found in current branch"
              exit 1
            fi
          fi

          pnpm install --frozen-lockfile --prefer-offline

      - name: Run changeset version
        if: ( github.event_name == 'push' && github.ref_name == 'main') || github.event_name == 'pull_request' || github.event_name == 'merge_group'
        uses: milaboratory/github-ci/actions/shell@v4-beta
        with:
          run: |
            pnpm run version-packages

      - name: Run build for - ${{ matrix.step }}
        shell: bash
        env:
          PRE_CALCULATED_STEP: ${{ matrix.step }}
        run: |
          pnpm run build --filter="${PRE_CALCULATED_STEP}"
    outputs:
      status: 'completed'

  build-test-publish:
    name: unified (build test publish)
    runs-on: ${{ inputs.gha-runner-label }}
    needs:
      - check-changesets
      - metadata
      - pre-calculated-build
    if: >
      !failure() && !cancelled() &&
      (
        needs.pre-calculated-build.result == 'success' ||
        needs.pre-calculated-build.result == 'skipped'
      ) &&
      (
        needs.check-changesets.result == 'success' ||
        needs.check-changesets.result == 'skipped'
      )
    permissions:
      id-token: write
      packages: write
      contents: write
      pull-requests: write
      issues: read

    steps:
      - id: context
        uses: milaboratory/github-ci/actions/context@v4-beta

      - uses: milaboratory/github-ci/actions/env@v4-beta
        with:
          inputs: ${{ inputs.env }}
          secrets: ${{ secrets.env }}

      - name: Generate Zen Artisan Token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.GH_ZEN_APP_ID }}
          private-key: ${{ secrets.GH_ZEN_APP_PRIVATE_KEY }}

      - uses: actions/checkout@v4
        with:
          lfs: ${{ inputs.checkout-git-lfs }}
          submodules: ${{ inputs.checkout-submodules }}
          token: ${{ steps.app-token.outputs.token }}
          fetch-depth: '0'

      - name: Check infrastructure requirements for publication
        uses: milaboratory/github-ci/actions/node/require-latest@v4-beta
        with:
          packages: |
            @platforma-sdk/block-tools

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_CI_IAM_MONOREPO_SIMPLE_ROLE }}
          role-duration-seconds: ${{ inputs.aws-login-duration }}
          aws-region: ${{ inputs.aws-region }}

      - id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
        with:
          mask-password: 'true'

      - name: Login to Quay.io
        if: inputs.docker-quay-push && env.QUAY_USERNAME != '' && env.QUAY_ROBOT_TOKEN != ''
        uses: docker/login-action@v3
        with:
          registry: quay.io
          username: ${{ env.QUAY_USERNAME }}
          password: ${{ env.QUAY_ROBOT_TOKEN }}
          ecr: false

      - name: Login to Docker GA
        if: inputs.docker-ga-push && env.QUAY_USERNAME != '' && env.QUAY_ROBOT_TOKEN != ''
        uses: docker/login-action@v3
        with:
          registry: containers.pl-open.science
          username: ${{ env.QUAY_USERNAME }}
          password: ${{ env.QUAY_ROBOT_TOKEN }}
          ecr: false

      - name: Prepare environment for Golang when requested
        if: inputs.golang-version != ''
        uses: milaboratory/github-ci/actions/golang/prepare@v4-beta
        with:
          golang-version: ${{ inputs.golang-version }}
          cache-version: ${{ inputs.cache-version }}
          cache-dependency-hashfiles-path: ${{ inputs.golang-cache-hashfiles-path }}

      - name: Prepare environment for building a NodeJS application
        uses: milaboratory/github-ci/actions/node/prepare-pnpm@v4-beta
        env:
          PNPM_VERSION: ${{ needs.metadata.outputs.pnpm-version }}
        with:
          node-version: ${{ inputs.node-version }}
          cache-version: ${{ inputs.cache-version }}
          pnpm-version: ${{ env.PNPM_VERSION || inputs.pnpm-version }}
          cache-hashfiles-search-path: ${{ inputs.cache-hashfiles-search-path }}
          npmrc-config: ${{ inputs.npmrc-config }}

      - uses: milaboratory/github-ci/actions/turborepo/cache-s3@v4-beta
        with:
          storage-provider: 's3'
          storage-path: ${{ env.AWS_CI_TURBOREPO_S3_BUCKET }}
          team-id: ${{ inputs.team-id }}

      - name: Install NodeJS packages with pnpm
        shell: bash
        env:
          NODE_AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NPMJS_TOKEN: ${{ env.NPMJS_TOKEN  }}
          DEFAULT_BRANCH: origin/${{ inputs.changeset-default-branch }}

        run: |
          if git diff --name-only ${DEFAULT_BRANCH}..HEAD | grep -q -E '^pnpm-workspace.yaml$'; then
            # Changes in pnpm-workspace.yaml have to be accompanied by pnpm-lock.yaml update
            if ! git diff --name-only ${DEFAULT_BRANCH}..HEAD | grep -q -E '^pnpm-lock.yaml$'; then
              echo "Changes in pnpm-workspace.yaml detected, but no updates in pnpm-lock.yaml were found in current branch"
              exit 1
            fi
          fi

          pnpm install --frozen-lockfile --prefer-offline

      - name: Run changeset version
        if: ( github.event_name == 'push' && github.ref_name == 'main') || github.event_name == 'pull_request' || github.event_name == 'merge_group'
        shell: bash
        run: |
          pnpm run version-packages

      - name: Get changed files staged and unstaged
        if: github.event_name == 'push'
          && github.ref_name == 'main'
        id: check-changes
        shell: bash
        run: |
          # Check for tracked files
          TRACKED_FILES=$(git diff --diff-filter=ACMUXTR --name-only)
          # Check for untracked files
          UNTRACKED_FILES=$(git ls-files --others --exclude-standard)
          # Check for unstaged deleted files
          UNSTAGED_DELETED_FILES=$(git ls-files --deleted)

          if [ -n "${TRACKED_FILES}" ] || [ -n "${UNTRACKED_FILES}" ] || [ -n "${UNSTAGED_DELETED_FILES}" ]; then
            echo "Local changes detected but not committed."
            echo "has-changes=1" >> $GITHUB_OUTPUT
            echo "Tracked files:"
            echo "${TRACKED_FILES}"
            echo "Untracked files:"
            echo "${UNTRACKED_FILES}"
            echo "Unstaged deleted files:"
            echo "${UNSTAGED_DELETED_FILES}"
          else
            echo "No local changes detected."
            echo "has-changes=0" >> $GITHUB_OUTPUT
          fi

      - name: Run build
        uses: milaboratory/github-ci/blocks/monorepo/build-and-test-pnpm@v4-beta
        env:
          NODE_AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NPMJS_TOKEN: ${{ env.NPMJS_TOKEN  }}
          PNPM_VERSION: ${{ needs.metadata.outputs.pnpm-version }}
        with:
          build-script-name: ${{ inputs.build-script-name }}
          tests: 'false'
          test-script-name: ${{ inputs.test-script-name }}
          pnpm-recursive-build: ${{ inputs.pnpm-recursive-build }}
          pnpm-recursive-tests: ${{ inputs.pnpm-recursive-tests }}
          pnpm-build-args: ${{ inputs.pnpm-build-args }}
          pnpm-tests-args: ${{ inputs.pnpm-tests-args }}
          test-coverage: ${{ inputs.test-coverage }}
          test-coverage-reports: ${{ inputs.test-coverage-reports }}
          test-results-reports: ${{ inputs.test-results-reports }}

      - name: Run tests
        id: test
        uses: milaboratory/github-ci/blocks/monorepo/test-pl-docker-pnpm@v4-beta
        if: inputs.test
        env:
          PL_ADDRESS: "http://127.0.0.1:6345"
          PL_TEST_USER: ${{ env.PL_CI_TEST_USER }}
          PL_TEST_PASSWORD: ${{ env.PL_CI_TEST_PASSWORD }}
          NODE_AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NPMJS_TOKEN: ${{ env.NPMJS_TOKEN  }}
          PNPM_VERSION: ${{ needs.metadata.outputs.pnpm-version }}
          # PL_DOCKER_REGISTRY_PUSH_TO: "quay.io/milaboratories/pl-containers" # until MILAB-4008 is resolved
        with:
          test-script-name: ${{ inputs.test-script-name }}
          test-dry-run-script-name: ${{ inputs.test-dry-run-script-name }}
          test-skip-dry-run: ${{ inputs.test-skip-dry-run }}
          pnpm-recursive-tests: ${{ inputs.pnpm-recursive-tests }}
          pnpm-tests-args: ${{ inputs.pnpm-tests-args }}
          pl-start-service: ${{ inputs.pl-start-for-tests }}
          pl-docker-registry: ${{ format('{0}/{1}', steps.login-ecr.outputs.registry, 'pl') }}
          pl-docker-tag: ${{ inputs.pl-docker-tag }}
          pl-test-assets-dir: ${{ inputs.pl-test-assets-dir }}
          pl-log-level: ${{ inputs.pl-log-level }}
          test-coverage: ${{ inputs.test-coverage }}
          test-coverage-reports: ${{ inputs.test-coverage-reports }}
          test-results-reports: ${{ inputs.test-results-reports }}

      - name: Save Turbo S3 cache status for monitoring
        if: always() && inputs.cache-monitoring && inputs.test && inputs.test-skip-dry-run != 'true'
        uses: milaboratory/github-ci/actions/shell@v4-beta
        with:
          run: |
            if [ -f ./test-dry-run.json ]; then
              CACHE_STATUS=$(tail -n +5 ./test-dry-run.json | jq -c '{
                ran_without_cache: (.tasks | map(select(.task == "test")) | any((.cache.status == "MISS") and (.command != "<NONEXISTENT>"))),
                cache_stats: (.tasks | map(select(.task == "test")) | map(.cache.status) | reduce .[] as $status ({HIT: 0, MISS: 0}; .[$status] += 1)),
                cache_type: "turbo-remote-s3",
                workflow_run_id: ${{ github.run_id }},
                workflow_run_number: ${{ github.run_number }},
                event_name: "${{ github.event_name }}",
                ref: "${{ github.ref }}",
                sha: "${{ github.sha }}",
                timestamp: now
              }')
              echo "${CACHE_STATUS}" > cache-status.json
              echo "Turbo S3 cache status saved: ${CACHE_STATUS}"
            fi

      - name: Upload Turbo S3 cache status artifact
        if: always() && inputs.cache-monitoring && inputs.test && inputs.test-skip-dry-run != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: turbo-s3-cache-status-${{ github.run_id }}
          path: cache-status.json
          retention-days: 30
          if-no-files-found: ignore

      - name: Run build (before publish)
        uses: milaboratory/github-ci/blocks/monorepo/build-and-test-pnpm@v4-beta
        env:
          NODE_AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NPMJS_TOKEN: ${{ env.NPMJS_TOKEN  }}
          PNPM_VERSION: ${{ needs.metadata.outputs.pnpm-version }}
          # PL_DOCKER_REGISTRY_PUSH_TO: "quay.io/milaboratories/pl-containers" # until MILAB-4008 is resolved
        with:
          build-script-name: ${{ inputs.build-before-publish-script-name || inputs.build-script-name }}
          tests: 'false'
          test-script-name: ${{ inputs.test-script-name }}
          pnpm-recursive-build: ${{ inputs.pnpm-recursive-build }}
          pnpm-recursive-tests: ${{ inputs.pnpm-recursive-tests }}
          pnpm-build-args: ${{ inputs.pnpm-build-args }}
          pnpm-tests-args: ${{ inputs.pnpm-tests-args }}
          test-coverage: ${{ inputs.test-coverage }}
          test-coverage-reports: ${{ inputs.test-coverage-reports }}
          test-results-reports: ${{ inputs.test-results-reports }}

      - name: Perform security scan checks before publication
        uses: milaboratory/github-ci/actions/docker/scan-pnpm-repo@v4-beta

      - name: Get GitHub App User ID
        if: steps.check-changes.outputs.has-changes == '1'
        id: get-user-id
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: echo "user-id=$(gh api "/users/${{ steps.app-token.outputs.app-slug }}[bot]" --jq .id)" >> "$GITHUB_OUTPUT"

      - name: Commit changed files to main
        uses: milaboratory/github-ci/actions/shell@v4-beta
        if: steps.check-changes.outputs.has-changes == '1'
        env:
          USER_ID: ${{ steps.get-user-id.outputs.user-id }}
          APP_SLUG: ${{ steps.app-token.outputs.app-slug }}
        with:
          run: |
            git config --global user.name "${APP_SLUG}[bot]"
            git config --global user.email "${USER_ID}+${APP_SLUG}[bot]@users.noreply.github.com>"
            git checkout main
            git add .
            git commit -m "Auto-generated changes"
            git push

      - name: Publish npm package
        id: publish-to-private
        if: github.ref_name == 'main'
          && steps.check-changes.outputs.has-changes == '0'
          && inputs.publish-to-public == 'false'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NODE_AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NPMJS_TOKEN: ${{ env.NPMJS_TOKEN }}
          # PL_DOCKER_REGISTRY_PUSH_TO: "quay.io/milaboratories/pl-containers"  # until MILAB-4008 is resolved

        uses: changesets/action@v1
        with:
          publish: pnpm -r publish --no-git-checks

      - name: Publish npm package (public)
        id: publish-to-public
        if: github.ref_name == 'main'
          && steps.check-changes.outputs.has-changes == '0'
          && inputs.publish-to-public == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NODE_AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NPMJS_TOKEN: ${{ env.NPMJS_TOKEN }}
          # PL_DOCKER_REGISTRY_PUSH_TO: "quay.io/milaboratories/pl-containers"  # until MILAB-4008 is resolved

        uses: changesets/action@v1
        with:
          publish: pnpm -r publish --no-git-checks --access public

      - name: Create release with tag
        if: github.ref_name == 'main'
          && steps.check-changes.outputs.has-changes == '0'
          && inputs.create-tag == 'true'
        uses: milaboratory/github-ci/actions/release/create-with-tag@v4-beta
        env:
          NPM_PKG_VERSION: ${{ needs.metadata.outputs.npm-pkg-version }}
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          name: ${{ format('v{0}', env.NPM_PKG_VERSION) }}
          tag: ${{ format('v{0}', env.NPM_PKG_VERSION) }}
          commit: ${{ github.sha }}
          skipIfReleaseExists: true
          draft: false
          prerelease: false

    outputs:
      # Even constant outputs become initialized only after job start.
      # All outputs of skipped jobs are always empty.
      started: 'true'

  notify-slack-release:
    name: notify slack release
    runs-on: ubuntu-latest
    if: always() && inputs.notify-slack
    needs:
      - init
      - metadata
      - check-changesets
      - build-test-publish
      - pre-calculated-build
    steps:
      - id: search-tags
        if: always()
        uses: milaboratory/github-ci/actions/strings/json-list@v4-beta
        with:
          input: |
            release

      - uses: milaboratory/github-ci/blocks/notify/slack/release@v4-beta
        env:
          NPM_PKG_VERSION: ${{ needs.metadata.outputs.npm-pkg-version }}
        with:
          slack-bot-token: ${{ secrets.SLACK_BOT_TOKEN }}
          slack-channel: ${{ secrets.SLACK_CHANNEL }}
          job-status: |
            ${{ needs.pre-calculated-build.result }}
            ${{ needs.build-test-publish.result }}
            ${{ needs.check-changesets.result }}
          product-name: ${{ inputs.app-name }}
          override-version: ${{ format('{0}', env.NPM_PKG_VERSION) }}
          override-tag: ${{ format('v{0}', env.NPM_PKG_VERSION) }}
          search-tags: ${{ steps.search-tags.outputs.result }}

  monitor-cache-status:
    name: monitor Turbo S3 cache status
    runs-on: ubuntu-latest
    if: always() && inputs.cache-monitoring && inputs.test && inputs.test-skip-dry-run != 'true' && github.event_name == 'merge_group'
    needs:
      - build-test-publish
    permissions:
      actions: read
      contents: read
    # For testing: Temporarily lower threshold by adding env variable:
    # env:
    #   CACHE_MONITOR_THRESHOLD: '1'  # Default is 3, use 1 for testing
    steps:
      - name: Install GitHub CLI (if needed)
        uses: milaboratory/github-ci/actions/shell@v4-beta
        with:
          run: |
            # Check if gh is installed
            if command -v gh &> /dev/null; then
              echo "GitHub CLI (gh) is already installed: $(gh --version)"
            else
              echo "Installing GitHub CLI (gh)..."
              # Use official GitHub CLI action for installation
              # This works on both GitHub-hosted and self-hosted runners
              curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg
              sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg
              echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
              sudo apt-get update
              sudo apt-get install gh -y
            fi
            
            # Verify gh installation
            gh --version || (echo "::error::Failed to install or verify gh. Please install manually on self-hosted runner." && exit 1)

      - name: Generate Zen Artisan Token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.GH_ZEN_APP_ID }}
          private-key: ${{ secrets.GH_ZEN_APP_PRIVATE_KEY }}

      - name: Check recent merge queue runs for Turbo S3 cache misses
        id: check-cache
        uses: milaboratory/github-ci/actions/shell@v4-beta
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
          WORKFLOW_NAME: ${{ github.workflow }}
          REPO: ${{ github.repository }}
          BRANCH: ${{ github.ref_name }}
          EVENT_TYPE: ${{ github.event_name }}
          CACHE_MONITOR_THRESHOLD: ${{ env.CACHE_MONITOR_THRESHOLD || '3' }}
        with:
          run: |
            echo "=== Turbo S3 Cache Monitoring ==="
            echo "Checking recent merge queue workflow runs for Turbo S3 remote cache misses..."
            echo "Event type: ${EVENT_TYPE}"
            echo "Branch: ${BRANCH}"
            echo "Workflow: ${WORKFLOW_NAME}"
            echo "Repository: ${REPO}"
            echo "Alert threshold: ${CACHE_MONITOR_THRESHOLD} consecutive misses"
            echo ""
            
            # For merge_queue, we want to track consecutive runs in the merge queue
            # Get recent workflow runs filtered by merge_group event (last 15 runs to account for filtering)
            RUNS=$(gh run list \
              --workflow "${WORKFLOW_NAME}" \
              --repo "${REPO}" \
              --limit 15 \
              --json databaseId,conclusion,displayTitle,createdAt,event,headBranch \
              --jq 'map(select(.event == "merge_group")) | sort_by(.createdAt) | reverse | .[0:10]')
            
            RUN_COUNT=$(echo "${RUNS}" | jq 'length')
            echo "Found ${RUN_COUNT} recent merge_group runs"
            
            if [ "${RUN_COUNT}" -eq 0 ]; then
              echo "⚠️ No merge_group runs found - skipping cache monitoring"
              echo "This is normal if this is one of the first merge queue runs"
              {
                echo "alert=false"
                echo "consecutive_misses=0"
              } >> $GITHUB_OUTPUT
              exit 0
            fi
            
            echo "Analyzing cache status for these runs..."
            echo ""
            
            # Count consecutive merge queue runs without Turbo S3 cache
            CONSECUTIVE_MISSES=0
            MISS_RUNS=()
            
            for run_id in $(echo "${RUNS}" | jq -r '.[].databaseId'); do
              # Try to download Turbo S3 cache status artifact
              ARTIFACTS=$(gh run view "${run_id}" --repo "${REPO}" --json artifacts --jq '.artifacts[] | select(.name | startswith("turbo-s3-cache-status-")) | .name' | head -1)
              
              if [ -n "${ARTIFACTS}" ]; then
                echo "Checking merge queue run ${run_id} for Turbo S3 cache status..."
                ARTIFACT_DIR="/tmp/artifacts-${run_id}"
                gh run download "${run_id}" --repo "${REPO}" --name "${ARTIFACTS}" --dir "${ARTIFACT_DIR}" || true
                
                # gh run download places files directly in target directory
                if [ -f "${ARTIFACT_DIR}/cache-status.json" ]; then
                  CACHE_TYPE=$(jq -r '.cache_type // "unknown"' "${ARTIFACT_DIR}/cache-status.json")
                  RAN_WITHOUT_CACHE=$(jq -r '.ran_without_cache' "${ARTIFACT_DIR}/cache-status.json")
                  EVENT_NAME=$(jq -r '.event_name' "${ARTIFACT_DIR}/cache-status.json")
                  
                  # Only count merge_group runs with Turbo S3 cache misses
                  if [ "${CACHE_TYPE}" == "turbo-remote-s3" ] && [ "${EVENT_NAME}" == "merge_group" ] && [ "${RAN_WITHOUT_CACHE}" == "true" ]; then
                    CONSECUTIVE_MISSES=$((CONSECUTIVE_MISSES + 1))
                    RUN_NUMBER=$(jq -r '.workflow_run_number' "${ARTIFACT_DIR}/cache-status.json")
                    CACHE_STATS=$(jq -r '.cache_stats' "${ARTIFACT_DIR}/cache-status.json")
                    MISS_RUNS+=("Merge queue run #${RUN_NUMBER} (${CACHE_STATS})")
                    echo "Merge queue run #${RUN_NUMBER} ran without Turbo S3 cache"
                  elif [ "${RAN_WITHOUT_CACHE}" == "false" ] && [ "${EVENT_NAME}" == "merge_group" ]; then
                    # Found a merge queue run with cache hits, stop counting
                    RUN_NUMBER=$(jq -r '.workflow_run_number' "${ARTIFACT_DIR}/cache-status.json")
                    echo "Merge queue run #${RUN_NUMBER} had Turbo S3 cache hits - stopping consecutive count"
                    break
                  fi
                fi
              fi
            done
            
            echo ""
            echo "=== Summary ==="
            echo "Consecutive merge queue runs without Turbo S3 cache: ${CONSECUTIVE_MISSES}"
            echo "Alert threshold: ${CACHE_MONITOR_THRESHOLD}"
            
            if [ "${#MISS_RUNS[@]}" -gt 0 ]; then
              echo "Affected runs:"
              for run_info in "${MISS_RUNS[@]}"; do
                echo "  - ${run_info}"
              done
            fi
            
            # Alert if threshold or more consecutive merge queue runs without cache
            if [ "${CONSECUTIVE_MISSES}" -ge "${CACHE_MONITOR_THRESHOLD}" ]; then
              echo ""
              echo "::warning::Multiple consecutive merge queue runs (${CONSECUTIVE_MISSES}) executed without Turbo S3 remote cache"
              echo "::notice::This may indicate Turbo S3 cache connectivity issues, cache invalidation, or S3 bucket/configuration problems"
              echo "Affected merge queue runs: ${MISS_RUNS[*]}"
              echo "::notice::Check Turbo remote cache server logs and S3 bucket access/permissions"
              echo "::notice::Merge queue runs are sequential, so cache misses can significantly impact CI/CD performance"
              
              # Set output for potential notification
              {
                echo "alert=true"
                echo "consecutive_misses=${CONSECUTIVE_MISSES}"
              } >> $GITHUB_OUTPUT
            else
              echo ""
              echo "✅ Turbo S3 cache status for merge queue is healthy (${CONSECUTIVE_MISSES} consecutive misses, threshold: ${CACHE_MONITOR_THRESHOLD})"
              {
                echo "alert=false"
                echo "consecutive_misses=${CONSECUTIVE_MISSES}"
              } >> $GITHUB_OUTPUT
            fi

      - name: Prepare Slack notification payload
        if: steps.check-cache.outputs.alert == 'true' && inputs.notify-slack
        id: slack-payload
        uses: milaboratory/github-ci/actions/shell@v4-beta
        env:
          CONSECUTIVE_MISSES: ${{ steps.check-cache.outputs.consecutive_misses }}
          BRANCH: ${{ github.ref_name }}
          WORKFLOW: ${{ github.workflow }}
          REPO: ${{ github.repository }}
          SLACK_CHANNEL: ${{ secrets.SLACK_CHANNEL }}
        with:
          run: |
            # Use jq to safely construct JSON payload (jq is used elsewhere in monitoring script)
            PAYLOAD=$(jq -n \
              --arg channel "${SLACK_CHANNEL}" \
              --arg misses "${CONSECUTIVE_MISSES}" \
              --arg repo "${REPO}" \
              --arg workflow "${WORKFLOW}" \
              --arg branch "${BRANCH}" \
              '{
                channel: $channel,
                text: "⚠️ *Turbo S3 Remote Cache Alert - Merge Queue*\n\n\($misses) consecutive merge queue runs executed without Turbo S3 cache in \($repo)\n\n*Workflow:* \($workflow)\n*Branch:* \($branch)\n\n⚠️ *Impact:* Merge queue runs are sequential, so cache misses significantly slow down CI/CD pipeline\n\n*This may indicate:*\n• Turbo remote cache server connectivity issues\n• S3 bucket access/permission problems\n• Cache invalidation or configuration issues\n• Merge queue runs happening too quickly for cache to populate\n\n*Recommended actions:*\n• Check Turbo remote cache server logs\n• Verify S3 bucket access/permissions\n• Review cache configuration and team-id settings"
              }')
            
            ghwa_set_output "payload" "${PAYLOAD}"

      - name: Notify on Turbo S3 cache issues in merge queue (Slack)
        if: steps.check-cache.outputs.alert == 'true' && inputs.notify-slack
        uses: milaboratory/github-ci/actions/notify/slack/send@v4-beta
        with:
          token: ${{ secrets.SLACK_BOT_TOKEN }}
          method: chat.postMessage
          payload: ${{ steps.slack-payload.outputs.payload }}
